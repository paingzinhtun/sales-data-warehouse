# Sales Data Warehouse

## Project Overview
This project is a Sales Data Warehouse built using PostgreSQL. It follows a star schema design with fact and dimension tables, optimized for analytics and reporting. The project includes data cleaning, product performance analysis, and customer segmentation using Python (Pandas, SQLAlchemy) and Jupyter notebooks.

# Project Structure

/sales-data-warehouse
â”‚â”€â”€ README.md # Project overview
â”‚â”€â”€ schema.sql # SQL script to create tables
â”‚â”€â”€ sample_data.sql # SQL script with sample data
â”‚â”€â”€ queries.sql # Common queries for analysis
â”‚â”€â”€ docs/ # Documentation folder
â”‚ â”œâ”€â”€ schema_design.md # Explanation of the schema
â”‚ â”œâ”€â”€ optimization_tips.md # Performance best practices
â”‚â”€â”€ notebooks/ # Jupyter notebooks for analysis
â”‚ â”œâ”€â”€ data_cleaning.ipynb # Cleaning and preprocessing
â”‚ â”œâ”€â”€ product_performance.ipynb # Product performance analysis
â”‚ â”œâ”€â”€ customer_segmentation.ipynb # Customer insights
â”‚â”€â”€ data/ # Folder for cleaned and processed data
â”‚â”€â”€ ERD.png # Entity-Relationship Diagram

## 1ï¸âƒ£ Step 1: Set Up the Project

### Clone the repository:
```bash
git clone https://github.com/paingzinghtun/sales-data-warehouse.git  
cd sales-data-warehouse
```

### Install dependencies:
```bash
pip install pandas sqlalchemy psycopg2 jupyter
```

## 2ï¸âƒ£ Step 2: Database Schema Design

The warehouse follows a star schema:
- **Fact Table**: fact_sales
- **Dimension Tables**: dim_customer, dim_product, dim_date, dim_region

View the schema details in `docs/schema_design.md`.

Run `schema.sql` to create tables in PostgreSQL:
```bash
psql -U username -d sales_db -f schema.sql
````

## 3ï¸âƒ£ Step 3: Insert Sample Data

Load sample data into the database:
```bash
psql -U username -d sales_db -f sample_data.sql
```

## 4ï¸âƒ£ Step 4: Run SQL Queries for Analysis

Check total sales per product:
```bash
psql -U username -d sales_db -f queries.sql
```

## 5ï¸âƒ£ Step 5: Data Cleaning and Preprocessing

Open Jupyter Notebook:
```bash
jupyter notebook
```

Run `notebooks/data_cleaning.ipynb` to clean sales data and save it as `data/cleaned_sales_data.csv`.

## 6ï¸âƒ£ Step 6: Product Performance Analysis

Run `notebooks/product_performance.ipynb` to analyze top-selling products.


## 7ï¸âƒ£ Step 7: Customer Segmentation & Insights

Run `notebooks/customer_segmentation.ipynb` to analyze customer behavior.

## 8ï¸âƒ£ Step 8: Optimize Query Performance

Best practices for indexing, partitioning, and materialized views are in `docs/optimization_tips.md`.

Run `VACUUM ANALYZE` for PostgreSQL performance tuning.

## 9ï¸âƒ£ Step 9: Push Changes to GitHub

Update your repository:
```bash
git add .
git commit -m "Updated data analysis notebooks"
git push origin main
```

## ğŸ”¹ Technologies Used
- **PostgreSQL** â€“ Database for sales data
- **Python (Pandas, SQLAlchemy)** â€“ Data analysis
- **Jupyter Notebooks** â€“ Exploratory data analysis
- **Markdown & SQL** â€“ Documentation and queries

## ğŸ“Œ Future Improvements
- Add real-world datasets for more insights
- Implement real-time sales tracking
- Improve customer segmentation with Machine Learning

## ğŸ“§ Contact
For any queries or contributions, contact: paingzinhtun.deai@gmail.com




